# -*- coding: utf-8 -*-
"""DenoisingMNIST-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CBb0yuq-LdLhr8CP2KhXfPG9Q_FgBF93
"""

import torch
import torch.nn as nn
import numpy as np
from torch.utils.data import DataLoader, random_split
import torchvision.transforms as transforms
from torchvision.datasets import MNIST
from torchvision import models
import matplotlib.pyplot as plt
from PIL import Image

device = 'cuda' if torch.cuda.is_available() else 'cpu'

def add_gaussian_noise(image):
    noise = torch.randn_like(image) * 1 + 1
    noisy_image = image + noise
    noisy_image = torch.clamp(noisy_image, 0., 1.)  # ensure the values are between 0 and 1
    return noisy_image

def add_salt_pepper_noise(image, salt_prob=0.5, pepper_prob=0.5):
    noisy_image = image.clone()

    # Generate salt noise
    num_salt = int(np.ceil(salt_prob * image.numel()))
    salt_coords = [np.random.randint(0, max(i, 1), num_salt) for i in image.shape]
    noisy_image[salt_coords] = 1

    # Generate pepper noise
    num_pepper = int(np.ceil(pepper_prob * image.numel()))
    pepper_coords = [np.random.randint(0, max(i, 1), num_pepper) for i in image.shape]
    noisy_image[pepper_coords] = 0

    return noisy_image

def add_poisson_noise(image, scale=1.0, offset=1.0):
    noisy_image = torch.poisson((image + offset) * scale) / scale - offset
    noisy_image = torch.clamp(noisy_image, 0., 1.)  # ensure the values are between 0 and 1
    return noisy_image

def add_speckle_noise(image, mean=0.5, stddev=1):
    noise = torch.randn_like(image) * stddev + mean
    noisy_image = image + image * noise
    noisy_image = torch.clamp(noisy_image, 0., 1.)  # ensure the values are between 0 and 1
    return noisy_image


class NoisyMNIST(MNIST):
    def __init__(self, root, train=True, transform=None, noisy_transform=None, download=False):
        super().__init__(root, train=train, transform=transforms.ToTensor(), download=download)
        self.noisy_transform = noisy_transform
        self.user_transform = transform

    def __getitem__(self, index):
        img, target = super().__getitem__(index)

        if self.noisy_transform is not None:
            noisy_img = self.noisy_transform(img)
        if self.user_transform is not None:
            img = self.user_transform(img)
        return noisy_img, img




class BasicBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu1 = nn.ReLU(inplace=False)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.relu2 = nn.ReLU(inplace=False)

    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu1(out)
        out = self.conv2(out)
        out = self.bn2(out)
        out = out + residual
        out = self.relu2(out)
        return out


class GreatBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.basic_block1 = BasicBlock(in_channels, out_channels)
        self.basic_block2 = BasicBlock(out_channels, out_channels)
        self.relu = nn.ReLU(inplace=False)

    def forward(self, x):
        residual = x
        out = self.basic_block1(x)
        out = self.basic_block2(out)
        out = out + residual
        out = self.relu(out)
        return out




class ResidualModel(nn.Module):
    def __init__(self, in_channels):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1, bias=False)
        self.great_block1 = GreatBlock(64, 64)
        self.great_block2 = GreatBlock(64, 64)
        self.conv2 = nn.Conv2d(64, 1, kernel_size=3, padding=1, bias=False)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        out = self.conv1(x)
        out = self.great_block1(out)
        out = self.great_block2(out)
        out = self.conv2(out)
        out += x
        out = self.relu(out)
        return out



model = ResidualModel(1).to(device)
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.5, 0.999))

# transform = transforms.Lambda(lambda x: x / 255.0)

# noisy_transform = transforms.Compose([
#     transforms.Lambda(lambda x: x / 255.0),
#     transforms.Lambda(add_gaussian_noise),
# ])

# Carregar dataset MNIST e adicionar ruído gaussiano às imagens
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.ToTensor(),
    transforms.Lambda(lambda x: x.float()),  # Convert to FloatTensor
    transforms.Normalize((0.5,), (0.5,)),
    #transforms.Lambda(lambda x: x.repeat(3, 1, 1))  # repetir canal
])

noisy_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.ToTensor(),
    transforms.Lambda(lambda x: x.float()),  # Convert to FloatTensor
    transforms.Normalize((0.5,), (0.5,)),
    #transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # repetir canal
    transforms.Lambda(add_salt_pepper_noise)  # adicionar ruído
])


train_set = NoisyMNIST('./data', train=True, transform=transform, noisy_transform=noisy_transform, download=True)
test_set = NoisyMNIST('./data', train=False, transform=transform, noisy_transform=noisy_transform, download=True)

num_train = int(len(train_set) * 0.1)
num_valid = int(len(test_set) * 0.05)
num_test = num_valid

train_set, _ = random_split(train_set, [num_train, len(train_set) - num_train])
valid_set, _ = random_split(test_set, [num_valid, len(test_set) - num_valid])
test_set, _ = random_split(test_set, [num_test, len(test_set) - num_test])

train_loader = DataLoader(train_set, batch_size=64, shuffle=True)
valid_loader = DataLoader(valid_set, batch_size=64, shuffle=False)
test_loader = DataLoader(test_set, batch_size=64, shuffle=False)

dataiter = iter(train_loader)
noisy_imgs, clean_imgs = next(dataiter)

# Show the noisy images and the clean images
plt.figure(figsize=(10, 5))
for i in range(5):
    plt.subplot(2, 5, i+1)
    noisy_img = noisy_imgs[i].squeeze().numpy()
    plt.imshow(noisy_img, cmap='gray')
    plt.title('Noisy')
    plt.axis('off')

    plt.subplot(2, 5, i+6)
    clean_img = clean_imgs[i].squeeze().numpy()
    plt.imshow(clean_img, cmap='gray')
    plt.title('Clean')
    plt.axis('off')
plt.show()

num_epochs = 60
train_losses = []
valid_losses = []

for epoch in range(num_epochs):
    print(f"Training epoch {epoch+1}/{num_epochs}...")
    running_loss = 0.0

    for i, data in enumerate(train_loader, 0):
        inputs, targets = data
        inputs = inputs.float().to(device)
        targets = targets.float().to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    with torch.no_grad():
        for i, data in enumerate(valid_loader, 0):
            inputs, targets = data
            inputs = inputs.float().to(device)
            targets = targets.float().to(device)

            outputs = model(inputs)
            loss = criterion(outputs, targets)

            valid_losses.append(loss.item())

    train_losses.append(running_loss/len(train_loader))

print("Training completed!")

print("Evaluating model...")
test_losses = []
with torch.no_grad():
    for i, data in enumerate(test_loader, 0):
        inputs, targets = data
        inputs = inputs.float().to(device)
        targets = targets.float().to(device)

        outputs = model(inputs)
        loss = criterion(outputs, targets)

        test_losses.append(loss.item())

plt.plot(train_losses, label='Train')
plt.legend()
plt.title('Train Loss')
plt.show()

plt.plot(valid_losses, label='Validation')
plt.legend()
plt.title('Validation Loss')
plt.show()

plt.figure(figsize=(10, 5))
for i in range(5):
    plt.subplot(2, 5, i+1)
    plt.imshow(inputs[i].squeeze().cpu().numpy(), cmap='gray')
    plt.title('Input')
    plt.axis('off')

    plt.subplot(2, 5, i+6)
    plt.imshow(outputs[i].squeeze().detach().cpu().numpy(), cmap='gray')
    plt.title('Denoised')
    plt.axis('off')
plt.show()